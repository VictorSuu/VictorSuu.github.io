<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-31T16:01:50+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Matthias Humt</title><subtitle>PhD student at the German Aerospace Center (DLR)</subtitle><author><name>Matthias Humt</name></author><entry><title type="html">My daily routine</title><link href="http://localhost:4000/thought/2020/05/28/daily-routine.html" rel="alternate" type="text/html" title="My daily routine" /><published>2020-05-28T00:00:00+02:00</published><updated>2020-05-28T00:00:00+02:00</updated><id>http://localhost:4000/thought/2020/05/28/daily-routine</id><content type="html" xml:base="http://localhost:4000/thought/2020/05/28/daily-routine.html">&lt;h1 id=&quot;my-daily-routine&quot;&gt;My daily routine&lt;/h1&gt;
&lt;p&gt;I like a daily routine when working. In helps me to focus on &lt;em&gt;what&lt;/em&gt; I need to do without having to think about &lt;em&gt;how&lt;/em&gt; to do it. I find this especially helpful when I lack the motivation because I can simply put myself on the routine rails and start rolling. At least that’s the theory. I’ve never actually managed to keep up a routine for longer than a couple of weeks, be it that I forgot the building blocks of it or that it was too demanding for a rookie. To conquer the first problem, I’ll be writing the plan down here with the potential additional benefit to keep myself accountable as it’s out there, in the wild web world and to clarify my priorities.&lt;/p&gt;
&lt;p&gt;Of course the idea that such a routine could help in getting things done and even be happy while doing so is not mine. There are two books that put me on this path (though there are probably hundreds of these and millions of blog posts on the topic), both of which I’d like to summarize in a separate post later on:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.calnewport.com/books/deep-work/&quot;&gt;Deep Work&lt;/a&gt; by Cal Newport&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://jamesclear.com/atomic-habits&quot;&gt;Atomic Habits&lt;/a&gt; by James Clear&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So why should you read this if it’s mostly for myself? I have no idea. Yet here you are, so let’s continue.&lt;/p&gt;
&lt;h2 id=&quot;rise-and-shine&quot;&gt;1. Rise and shine&lt;/h2&gt;
&lt;p&gt;I try to get up early because I like the morning atmosphere and because it’s the time where I’m the most motivated and productive. 6 am would be awesome, but usually I only manage 7 am, even though I try to go to bed at 10 pm. It was quite difficult to admit to myself that I should need so much sleep.&lt;/p&gt;
&lt;p&gt;Those morning hours are really valuable to me so I should try to do the most difficult things here, either those which require a lot of concentration or a lot of motivation or both. It shouldn’t be things like answering difficult emails or researching stuff on the internet though, as this will just make me exhausted and grumpy.&lt;/p&gt;
&lt;h2 id=&quot;lon&quot;&gt;2. Léon&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Léon&lt;/em&gt; is an awesome movie. And the main protagonist (with the same name) does some exercise every morning to keep fit. Yes, he is a killer so his life depends on being agile and you are what again, a PhD student? You might rightfully ask and you would be right, but come to think of it, my life also depends on keeping fit as it probably will be much shorter otherwise. It also just feels good when sitting in front of a screen all day.&lt;/p&gt;
&lt;p&gt;I’m not a morning sports person though, I’ve tried. And after breakfast I’m too lazy as well. So I’ve decided to do some exercises every day at 11 am. Afterwards I try to mediate for 10 minutes. I use the &lt;a href=&quot;https://wakingup.com/&quot;&gt;&lt;em&gt;Waking Up&lt;/em&gt;&lt;/a&gt; app by &lt;em&gt;Sam Harris&lt;/em&gt;. If you think meditation is weird and only for monks I invite you to read &lt;a href=&quot;https://themindfulgeek.com/&quot;&gt;&lt;em&gt;The Mindful Geek&lt;/em&gt;&lt;/a&gt; by &lt;em&gt;Michael W. Taft&lt;/em&gt; or, if you have less time, &lt;a href=&quot;https://samharris.org/how-to-meditate/&quot;&gt;this article&lt;/a&gt; by &lt;em&gt;Sam Harris&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&quot;lunch&quot;&gt;3. Lunch&lt;/h2&gt;
&lt;p&gt;I usually eat rather late during the afternoon and then I’m doing with eating for the day. I sleep better without dinner and I’m also extremely hungry in the morning this way which helps me to get out of bed. Right now I’m working from home and I enjoy cooking which allows my mind to rest for a little while. I like to take a long break at around one or two pm to put on a podcast or some music and prepare something tasty.&lt;/p&gt;
&lt;p&gt;Afterwards, it’s nap time. No, seriously, I’m usually completely useless after lunch and just wait for the day to end. Therefore, I like to take a 15-20 minutes nap and emerge almost as good as new. I really think there should be places to do so at every workplace. I lose a quarter to a third of an hour but gain at least two to three productive hours.&lt;/p&gt;
&lt;h2 id=&quot;wrapping-up&quot;&gt;4. Wrapping up&lt;/h2&gt;
&lt;p&gt;After lunch, even with a short nap under my belt, I’m not as focused or motivated as in the morning. I therefore like to do more manually tasks here like programming, writing emails, collecting resources etc. When I’m satisfied with my daily progress, or just exhausted, I check what I’ve accomplished and plan the next day. This helps me to forget about work afterwards and to pick up where I left of without having to think too much about it.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;So there you (and I) are, my daily routine. I might come back here once in a while to update this with new insights I obtained about what works best for me. Below I give a once-glance overview of the prose above.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wake up at around 7 am.&lt;/li&gt;
&lt;li&gt;Do cognitively demanding work.&lt;/li&gt;
&lt;li&gt;Do some exercises.&lt;/li&gt;
&lt;li&gt;Meditate.&lt;/li&gt;
&lt;li&gt;Prepare a nice lunch, eat, take a short nap.&lt;/li&gt;
&lt;li&gt;Get less demanding menial or manual stuff done.&lt;/li&gt;
&lt;li&gt;Organize your progress and plan for the next day.&lt;/li&gt;
&lt;li&gt;Forget about work for the day.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Matthias Humt</name></author><category term="[&quot;thought&quot;]" /><category term="life" /><category term="work" /><category term="habits" /><summary type="html">My daily routine</summary></entry><entry><title type="html">What makes a good article?</title><link href="http://localhost:4000/thought/2020/05/28/writing-good-articles.html" rel="alternate" type="text/html" title="What makes a good article?" /><published>2020-05-28T00:00:00+02:00</published><updated>2020-05-28T00:00:00+02:00</updated><id>http://localhost:4000/thought/2020/05/28/writing-good-articles</id><content type="html" xml:base="http://localhost:4000/thought/2020/05/28/writing-good-articles.html">&lt;h1 id=&quot;what-makes-a-good-article&quot;&gt;What makes a good article?&lt;/h1&gt;
&lt;p&gt;I’ve been thinking more about what makes a good article, especially one explaining a difficult topic. As usual, these things only occurred to me after I started writing myself and now I want to collect them here for reference and to remind myself.&lt;/p&gt;
&lt;h2 id=&quot;clear-writing&quot;&gt;1. Clear writing&lt;/h2&gt;
&lt;p&gt;This might sound obvious, but the most important variable that decides if an article is of use to anyone is clear writing. Clear writing obviously involves sentences that make sense but more subtly it also involves structure and choice of words. I sometimes read articles that contain a great amount of information but hide it behind complicated language and scatter it seemingly at random on the page.&lt;/p&gt;
&lt;p&gt;While the latter is probably simply due to laziness or an oversight, the former is often used deliberately in an attempt to give the content credibility beyond what is warranted by its inherent information. See this last sentence? I sounds great and really deep due to the use of scholarly words and complicated structure. Here is what it would sound like if the primary goal was to bring across your point:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Information is often presented without structure due to laziness or because the author didn’t notice. Additionally, complicated structure or choice of words is sometimes used in an attempt to hide a lack of novelty or rigor.&lt;/em&gt; It’s a bit longer and less elegant but easier to parse. I’m not saying that everything should be written like a computer program, that would be a horrible fate for any good novel. But when trying to explain a difficult subject, your goal is to help other people understand and to make potential flaws or mistakes obvious so that they can be spotted (either by yourself while writing or by someone else reading it) and fixed easily. An explanation needs to be easy to follow and correct, not inspiring (except for its content maybe).&lt;/p&gt;
&lt;h2 id=&quot;time-amp-words&quot;&gt;2. Time &amp;amp; Words&lt;/h2&gt;
&lt;p&gt;Ever started reading an interesting article and stopped half way because you didn’t expect it to take so long and you have a million other things to do? Right, but how could you have anticipated this? While you might have been able to make an educated guess by checking its length and approximately knowing your reading speed, this is a cumbersome and imprecise. And you’d probably just forget to do it.&lt;/p&gt;
&lt;p&gt;That’s why I really like the idea to put an approximate reading time at the top of an article. Of course this time is affected by your reading speed and understanding of the presented material, but it’s for sure a lot better than nothing. Alternatively (or additionally) a word count can already be useful if you have a rough idea of your own reading speed and is usually quite straight forward to incorporate for the author, as most writing programs already provide a word count.&lt;/p&gt;
&lt;h2 id=&quot;visualization&quot;&gt;3. Visualization&lt;/h2&gt;
&lt;p&gt;You know how the saying goes, so I’m not going to spell it out here, though of course it’s true. I love visualizations of difficult to grasp concepts. It is really amazing how one can struggle to understand something for hours, days, weeks month or even years and then get it in an instance due to an innocent sketch or animation. And I don’t think there is enough of this out there.&lt;/p&gt;
&lt;p&gt;Sometimes I get the impression that there is a hidden agreement to not visualize certain topics. The reason might be that it is too difficult (though I would bet that’s not true but probably just tricky or a lot of work) or, worse, it is perceived as cheating or a cheap way out. “&lt;em&gt;I’ve spend years to get to an intuitive understanding of such and such and it can’t, no, it shouldn’t be replaced by a simple image!&lt;/em&gt;” proponents of this thought roller coaster might say (but probably just think).  Be that as it may, I think &lt;em&gt;everything&lt;/em&gt; should be visualized &lt;em&gt;all the time&lt;/em&gt;. It never hurts.&lt;/p&gt;
&lt;p&gt;Luckily the situation is improving due to the internet, where one can add as many large color images as one likes or even put animations which can even be interactive! Here are some outstanding examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/featured&quot;&gt;3Blue1Brown&lt;/a&gt;&lt;/strong&gt;: &lt;em&gt;Three blue one brown&lt;/em&gt; is the artistic name of &lt;em&gt;Grant Sanderson&lt;/em&gt; and his YouTube channel where he explains math (and other topics, though mostly math) using amazing visualization (which he programs in Python which is insane).
&lt;ul&gt;
&lt;li&gt;Check out this explanation of &lt;a href=&quot;https://www.3blue1brown.com/neural-networks&quot;&gt;Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Or this &lt;a href=&quot;https://eater.net/quaternions&quot;&gt;interactive explanation of quaternions&lt;/a&gt; he did with &lt;em&gt;Ben Eater&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://distill.pub/&quot;&gt;Distill&lt;/a&gt;&lt;/strong&gt;: The first peer-reviewed online journal with focus on visualization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://colah.github.io&quot;&gt;Colah’s blog&lt;/a&gt;&lt;/strong&gt;: One of my personal heroes. Quote: &lt;em&gt;“I want to understand things clearly, and explain them well.”&lt;/em&gt; Yes, exactly!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/user/Kurzgesagt/featured&quot;&gt;Kurzgesagt - In a Nutshell&lt;/a&gt;&lt;/strong&gt;: Another super cool YouTube channel, explaining science topics with outstanding animations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;discussion&quot;&gt;4. Discussion&lt;/h2&gt;
&lt;p&gt;Everyone makes mistakes. Especially if the topic is difficult, relies on a lot of background knowledge or is still in it’s infancy. While four eyes see more than two, a million see even more (a bit of wishful thinking here from my side; very unlikely that a million eyes will ever see this page). And some of those eyes pass their information on to brains which are trained on very specific fields which might only appear in a single sentence of an entire article. If I, for example, write about Deep Learning, there is so much to get wrong. The subject is difficult, relies on in depth knowledge of probability theory, statistic, linear algebra and calculus and is also still a very young field of research.&lt;/p&gt;
&lt;p&gt;All this is to say: There has to be a way do discuss articles with the author or between readers. While the author can get valuable feedback and iron out typos and other mistakes, the reader can ask about specific points that remain unclear which might help others who stumble upon the article later in time. This is also why I think it is much more useful to have an open format for discussion which is directly linked to each article instead of just providing an email address.&lt;/p&gt;
&lt;h2 id=&quot;resources&quot;&gt;5. Resources&lt;/h2&gt;
&lt;p&gt;Adding a footnote or link to additional resources can be really helpful in a article if the author didn’t have enough space, time or motivation to explain a topic in a way that you could understand it. The same is true for further reading material, even though it always gives me some anxiety because I feel like I have to read everything provided.&lt;/p&gt;
&lt;p&gt;If the article is long and there are lots of resources given, it can be difficult to find that one sentence again where the link to a specific paper or video was provided. I therefore like to have a dedicated resource section at the end of an article collecting and sorting everything that was previously mentioned to make it easy to keep exploring after your done reading. Of course this only makes sense if there are actually a lot of references and they are not already bundled in a dedicated section (e.g. &lt;em&gt;Related Work&lt;/em&gt; in a paper).&lt;/p&gt;
&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing thoughts&lt;/h2&gt;
&lt;p&gt;I’m often still astonished at the amount of great content out there waiting to be discovered for free. During my studies I discovered that most of the time, a topic taught in class had been explained elsewhere already and often a lot better. Following a few Standford classes on YouTube I gained the insight, that the content taught and the students learning it were actually quite similar to what I was used to during my own studies in Germany. I had also imagined everything to be at another level over there. This is in part why I started my own blog. Maybe I’ll be able to participate in this great exchange of knowledge, whether standing on the shoulders of giants or on those of a first semester student who just happened to have a nag for explaining one little thing extremely well.&lt;/p&gt;
&lt;p&gt;That’s it for now. I’m sure I will come across other great ideas to incorporate into articles to make them even more enjoyable and useful. If I do, I’ll update this post accordingly. Now it’s time incorporate these best practices into my own writing.&lt;/p&gt;</content><author><name>Matthias Humt</name></author><category term="[&quot;thought&quot;]" /><category term="writing" /><category term="explanation" /><summary type="html">What makes a good article?</summary></entry><entry><title type="html">Robotics &amp;amp; machine learning PhD topics list</title><link href="http://localhost:4000/brainstorming/2020/05/13/topic-list.html" rel="alternate" type="text/html" title="Robotics &amp; machine learning PhD topics list" /><published>2020-05-13T00:00:00+02:00</published><updated>2020-05-13T00:00:00+02:00</updated><id>http://localhost:4000/brainstorming/2020/05/13/topic-list</id><content type="html" xml:base="http://localhost:4000/brainstorming/2020/05/13/topic-list.html">&lt;h1 id=&quot;robotics-amp-machine-learning-phd-topics-list&quot;&gt;Robotics &amp;amp; machine learning PhD topics list&lt;/h1&gt;
&lt;p&gt;This is an ongoing list of potential topics for my PhD. This is mostly written for myself, to order and collect my thoughts. But maybe you are interested in similar topics in which case we can explore this exciting landscape together. Whatever ends up in this list will have a really high chance to be machine learning related though. Definitely feel free to drop me a comment if you have other cool ideas.&lt;/p&gt;
&lt;h2 id=&quot;bayesian-deep-learning&quot;&gt;1. Bayesian Deep Learning&lt;/h2&gt;
&lt;p&gt;This is of course a super large field already, but also an extremely interesting one. I’ve been working on a technique called &lt;em&gt;Laplace Approximation&lt;/em&gt; during my Masters’ thesis where I applied it to deep neural networks to transform them post hoc into Bayesian neural networks.&lt;/p&gt;
&lt;p&gt;There are a myriad of other methods to achieve this, like &lt;em&gt;Monte Carlo dropout&lt;/em&gt;, ensemble learning and variational approaches.&lt;/p&gt;
&lt;h3 id=&quot;pros&quot;&gt;Pros:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Extremely young field, even younger than deep learning, so there is still a lot to discover.
&lt;ul&gt;
&lt;li&gt;Related: Booming field so potentially high impact. Though that’s usually of little interest to me.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Very important for deep learning to make algorithms deployed in the real world more reliable and therefore less dangerous. I really like the idea to work on AI safety from this angle.&lt;/li&gt;
&lt;li&gt;Principled yet applied. Bayesian probability theory is mature and technical but can be nicely applied to deep learning so it should be a great mix of theory and application.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;cons&quot;&gt;Cons:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Too large. You can’t just study “Bayesian Deep Learning”. I would have to focus on a much smaller subfield, but I’ve no idea yet what that could be.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;topics&quot;&gt;Topics:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reliable and fast uncertainty estimation for robotics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Uncertainty estimation for robust robotic perception&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;combining-model-and-data-driven-methods&quot;&gt;2. Combining model and data driven methods&lt;/h2&gt;
&lt;p&gt;I’ve studied robotics for my Masters’ degree and consequently now work with robots. A robot is a very complex system, combining mechanical, electrical and software engineering. A lot of this is well studied and deterministic, following established physical rules. For example, knowing all the parameters of a robotic arm like joint friction, motor torque and the initial position, one can easily compute the motion of the arm when applying voltage to the motors, or reversely, the voltage required to perform a desired motion.&lt;/p&gt;
&lt;p&gt;Enter machine learning, or even worse, deep learning. Exit determinism. Because deep learning methods are data driven, learning statistical regularities from it without or with minimal human oversight, the results are inherently opaque to us. Worse, the less we know beforehand, the more data we typically need to get our system to do what we want.&lt;/p&gt;
&lt;p&gt;The solution: Apply as much prior knowledge about the system as possible in the form of physical models and only learn the remaining unsolved parts, i.e. those for which we don’t have closed form equations. In our example from above this might translate into an algorithm that already knows how to move the arm around by applying certain voltages to certain motors in certain joints an when given the task to, e.g., solve a Rubik’s cube, it only needs to learn the solution to the problem itself, i.e. what to turn when and where, instead of also having to learn how to move.&lt;/p&gt;
&lt;p&gt;This is a lot like an adult solving a problem vs a baby. While the baby first needs to learn how to move its extremities and what “solve the Rubik’s cube” even means, the adult can directly proceed to twisting and turning.&lt;/p&gt;
&lt;h3 id=&quot;pros-1&quot;&gt;Pros:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Quite the rage at the moment. As large data sets are expensive to create there is high demand for more efficient methods.&lt;/li&gt;
&lt;li&gt;Especially relevant in robotics due to the close connection of well established “old school” fields such as mechanical and electrical engineering and cutting edge deep learning for perception.&lt;/li&gt;
&lt;li&gt;Elegant, as we don’t reinvent the wheel for each task but instead stand on the shoulders of giants.&lt;/li&gt;
&lt;li&gt;Suits me, as I have some prior knowledge due to a Bachelor’s degree in mechanical engineering.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;cons-1&quot;&gt;Cons:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Difficult because one needs in depth knowledge of machine learning &lt;em&gt;and&lt;/em&gt; physics.&lt;/li&gt;
&lt;li&gt;Also by far too large. I would have to find a concrete use case or much smaller subtask.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;topics-1&quot;&gt;Topics:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian motion learning through model priors&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;ai-safety&quot;&gt;3. AI Safety&lt;/h2&gt;
&lt;p&gt;From the paper &lt;a href=&quot;https://arxiv.org/pdf/1606.06565.pdf&quot;&gt;Concrete Problems in AI Safety&lt;/a&gt;: &lt;em&gt;Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (“avoiding side effects” and “avoiding reward hacking”), an objective function that is too expensive to evaluate frequently (“scalable supervision”), or undesirable behavior during the learning process (“safe exploration” and “distributional shift”). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I think AI safety is an extremely important field of research, particularly now, while we still have some time to get it right &lt;em&gt;before&lt;/em&gt; we deploy more and more machine learning solutions into the real world. It is also highly relevant for robotics, especially if those robots are to be used alongside humans. The authors discuss the following topics:&lt;/p&gt;
&lt;h3 id=&quot;topics-2&quot;&gt;Topics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Safe exploration.&lt;/strong&gt; &lt;em&gt;Can &lt;a href=&quot;http://karpathy.github.io/2016/05/31/rl/&quot;&gt;reinforcement learning&lt;/a&gt; (RL) agents learn about their environment without executing catastrophic actions?&lt;/em&gt; For example, can an RL agent learn to navigate an environment without ever falling off a ledge?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Robustness to distributional shift.&lt;/strong&gt; &lt;em&gt;Can machine learning systems be robust to changes in the data distribution, or at least fail gracefully?&lt;/em&gt; For example, can we build &lt;a href=&quot;https://www.tensorflow.org/versions/r0.9/tutorials/deep_cnn/index.html&quot;&gt;image classifiers&lt;/a&gt; that indicate appropriate uncertainty when shown new kinds of images, instead of confidently trying to use its &lt;a href=&quot;http://arxiv.org/abs/1412.6572&quot;&gt;potentially inapplicable&lt;/a&gt; learned model? -&amp;gt; Bayesian Deep Learning!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoiding negative side effects.&lt;/strong&gt; &lt;em&gt;Can we transform an RL agent’s &lt;a href=&quot;https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node9.html&quot;&gt;reward function&lt;/a&gt; to avoid undesired effects on the environment?&lt;/em&gt; For example, can we build a robot that will move an object while avoiding knocking anything over or breaking anything, without manually programming a separate penalty for each possible bad behavior?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoiding “reward hacking” and “&lt;a href=&quot;http://www.agroparistech.fr/mmip/maths/laurent_orseau/papers/ring-orseau-AGI-2011-delusion.pdf&quot;&gt;wireheading&lt;/a&gt;”.&lt;/strong&gt; &lt;em&gt;Can we prevent agents from “gaming” their reward functions, such as by distorting their observations?&lt;/em&gt; For example, can we train an RL agent to minimize the number of dirty surfaces in a building, without causing it to avoid looking for dirty surfaces or to create new dirty surfaces to clean up?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalable oversight.&lt;/strong&gt; &lt;em&gt;Can RL agents efficiently achieve goals for which feedback is very expensive?&lt;/em&gt; For example, can we build an agent that tries to clean a room in the way the user would be happiest with, even though feedback from the user is very rare and we have to use cheap approximations (like the presence of visible dirt) during training? The divergence between cheap approximations and what we actually care about is an important source of accident risk.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reinforcement learning, while super interesting, is not really my cup of tea so the second topic might be most interesting to me, especially as it plays nicely with Bayesian approaches. The last topic can also be applied to non-RL scenarios where it is usually called &lt;em&gt;active learning&lt;/em&gt; but with limited data.&lt;/p&gt;
&lt;h2 id=&quot;d-deep-learning&quot;&gt;4. 3D Deep Learning&lt;/h2&gt;
&lt;p&gt;The main difference (and problem) compared to 2D data like images is the permutation invariance of individual 3D data like point clouds. So given $N$ points, there are $N!$ ways to feed those to the learning algorithm while all should result in the same classification or segmentation result.&lt;/p&gt;
&lt;p&gt;Several ideas have been proposed to deal with this problem from taking multiple &lt;em&gt;views&lt;/em&gt; of the object and using a standard CNN on those to transforming the point cloud into a graph structure or working directly on the point cloud but making use of local neighborhoods.&lt;/p&gt;
&lt;h3 id=&quot;pros-2&quot;&gt;Pros&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Very young field so probably lots of opportunities to improve upon existing approaches.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;cons-2&quot;&gt;Cons&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It is not entirely clear to me if 3D data will actually be important in the near future because it might be that RGB based approaches (i.e. cameras) are enough for doing everything we care about (“humans don’t use depth sensors”).&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Matthias Humt</name></author><category term="brainstorming" /><category term="phd" /><category term="deep learning" /><category term="machine learning" /><category term="robotics" /><summary type="html">Robotics &amp;amp; machine learning PhD topics list</summary></entry><entry><title type="html">Hello World!</title><link href="http://localhost:4000/thought/2020/05/11/hello-world.html" rel="alternate" type="text/html" title="Hello World!" /><published>2020-05-11T00:00:00+02:00</published><updated>2020-05-11T00:00:00+02:00</updated><id>http://localhost:4000/thought/2020/05/11/hello-world</id><content type="html" xml:base="http://localhost:4000/thought/2020/05/11/hello-world.html">&lt;h1 id=&quot;hello-world&quot;&gt;Hello World!&lt;/h1&gt;
&lt;p&gt;Hello! You are reading my first, rather uninspirational, blog post. I’ve been toying with the idea of a personal blog for about a year now and finally found the time and courage to do it. While this is a personal blog, you most likely won’t find any posts about me, but rather about interesting stuff I’ve learned which I’d like to share in a visually pleasing and easy to understand way. Topics might range from machine learning (where I’m trying to get a PhD) to baking, bikes and building things.&lt;/p&gt;
&lt;p&gt;Well, still got a little personal right there! I’ll try to have at least one post a month, though this is rather a promise to myself than to you, dear reader. Hope to see you (and me) around soon.&lt;/p&gt;
&lt;p&gt;Best,&lt;br&gt;
Matthias.&lt;/p&gt;</content><author><name>Matthias Humt</name></author><category term="thought" /><category term="1st post" /><category term="is this thing on" /><summary type="html">Hello World!</summary></entry></feed>